---
title: "R Notebook"
output: html_notebook
---
```{r}
#Steps to this model:
#1) First fit log-logistic curves to each tdt curve (each temperature) for the data supplied
#2) Then fit a linear model to both log-logistic shape and scale vs temp
#3) Next, we deal with the fluctuating temp data:
#     start cumulative survival (S(t)) at 1 (S(t_0)=1)
#     for each timestep t_i:
#         Find the log-logistic shape and scale parameters corresponding to the temperature T_i at timestep t_i. These parameters give a cumulative survival function of time (time spent under the constant temperature used to make the LLogis TDT curve, which we will call t*. Not the fluctuating temperature t_i). This distribution has CDF F_w(t*), PDF f_w(t*), cumulative survival S_w(t*)=1-F_w(t*)
#         Find chance of surviving from time t_i-1 to t_i: 
#             i) First, we find: S_w^-1(S(t_i-1))=t*_i
#             ii) Calculate failure in that time interval f.rate_i=S(t_i)/S(t_i-1)
#             iii) Calculate cumulative mortality between t_i-1 and t_i as (t_i-(t_i-1))*f.rate_i
#             iiii)Let S_i=(S_i-1)-[(t_i-(t_i-1))*f_w(t*_i)]
#Note that this loop assumes the temperature is constant at T_i for the time interval from t_i-1 to t_i. You could alternatively take the max or average of the temperatures at these time points. 
#replace with shape="constant" if you want the model to assume constant shape
llogis.mod = function(TDT.dat,temp.dat,shape="linear"){
  #step 1
shape.vec = c()
shape.vec.var = c()
scale.vec = c()
scale.vec.var = c()
for (j in unique(TDT.dat$Tref)){
mod.j = flexsurvreg(Surv(time,event) ~ 1, data = TDT.dat[(TDT.dat$Tref==j),], dist=
                               "llogis")
shape.vec.var = c(shape.vec.var, mod.j$cov[[1,1]])
scale.vec.var = c(scale.vec.var, exp(mod.j$cov[[2,2]]))
shape.vec = c(shape.vec,mod.j$coefficients[[1]])
#exponentiate because the function flexsurvreg automatically puts scale on a log scale
scale.vec = c(scale.vec,exp(mod.j$coefficients[[2]]))
}

#step 2
shape.lm=lm(shape.vec~unique(TDT.dat$Tref))
shape.slope=lm(shape.vec~unique(TDT.dat$Tref))$coefficients[[2]]
shape.int=lm(shape.vec~unique(TDT.dat$Tref))$coefficients[[1]]
#constant shape lm
cons.shape.lm=lm(shape.vec~1)
cons.shape.int=cons.shape.lm$coefficients[[1]]
#note the log transformation
scale.lm=lm(log10(scale.vec)~unique(TDT.dat$Tref))
scale.slope=scale.lm$coefficients[[2]]
scale.int=scale.lm$coefficients[[1]]

shape.pars=c(shape.slope,shape.int,cons.shape.int)
logscale.pars=c(scale.slope,scale.int)

#predict under fluctuating temperatures with shape as a linear function of temperature
if (shape=="linear"){
#step 3
cum.surv = rep(NA,nrow(temp.dat))
cum.surv[1]=1
fail.rates = rep(0,nrow(temp.dat))
mean.list=c()
shape.list=c()
log.list=c()

for (i in 2:nrow(temp.dat)){
  T_i=temp.dat$Temperature[i]
  T_prev=temp.dat$Temperature[i-1]
  t_i=temp.dat$Time_min[i]
  t_prev=temp.dat$Time_min[i-1]
  t_diff=t_i-t_prev
  #untransform from log scale
  scale_i = 10^(scale.slope*mean(T_i,T_prev)+scale.int)
  shape_i = shape.slope*mean(T_i,T_prev)+shape.int
  mean.list=c(mean.list,((pi*scale_i)/shape_i)/(sin(pi/shape_i)))
  log.list=c(log.list,cum.surv[i-1])
  #inverse CDF
  prob = 1-cum.surv[i-1]
  t_star_i=scale_i*(prob/(1-prob))^(1/shape_i)
  #llogis pdf/failure rate
  #Get the proportion that made it th timestep i/prop that made it to i-1 to get the prop that died in the meantime
  fail.rates[i]=(1-pllogis(t_star_i,shape_i,scale_i))-(1-pllogis(t_star_i+t_diff,shape_i,scale_i))
  cum.surv[i]=cum.surv[i-1]-fail.rates[i]
}
med.tdt=temp.dat$Time_min[which.max(cum.surv<0.5)]
cum.surv.post=na.omit(cum.surv)
times.post=temp.dat$Time_min[1:length(cum.surv.post)]
expected.tdt=mean(-sum((cum.surv.post[2:length(cum.surv.post)]-cum.surv.post[1:(length(cum.surv.post)-1)])*times.post[2:length(cum.surv.post)]), -sum((cum.surv.post[2:length(cum.surv.post)]-cum.surv.post[1:(length(cum.surv.post)-1)])*times.post[1:(length(cum.surv.post)-1)]))
}

if (shape=="constant"){
 #step 3
cum.surv = rep(NA,nrow(temp.dat))
cum.surv[1]=1
fail.rates = rep(0,nrow(temp.dat))
mean.list=c()
shape.list=c()
log.list=c()

for (i in 2:nrow(temp.dat)){
  T_i=temp.dat$Temperature[i]
  T_prev=temp.dat$Temperature[i-1]
  t_i=temp.dat$Time_min[i]
  t_prev=temp.dat$Time_min[i-1]
  t_diff=t_i-t_prev
  #untransform from log scale
  scale_i = 10^(scale.slope*mean(T_i,T_prev)+scale.int)
  #this is the only line that is different
  shape_i = cons.shape.int
  mean.list=c(mean.list,((pi*scale_i)/shape_i)/(sin(pi/shape_i)))
  log.list=c(log.list,cum.surv[i-1])
  #inverse CDF
  prob = 1-cum.surv[i-1]
  t_star_i=scale_i*(prob/(1-prob))^(1/shape_i)
  #llogis pdf/failure rate
  #Get the proportion that made it th timestep i/prop that made it to i-1 to get the prop that died in the meantime
  fail.rates[i]=(1-pllogis(t_star_i,shape_i,scale_i))-(1-pllogis(t_star_i+t_diff,shape_i,scale_i))
  cum.surv[i]=cum.surv[i-1]-fail.rates[i]
}
med.tdt=temp.dat$Time_min[which.max(cum.surv<0.5)]
cum.surv.post=na.omit(cum.surv)
times.post=temp.dat$Time_min[1:length(cum.surv.post)]
expected.tdt=mean(-sum((cum.surv.post[2:length(cum.surv.post)]-cum.surv.post[1:(length(cum.surv.post)-1)])*times.post[2:length(cum.surv.post)]), -sum((cum.surv.post[2:length(cum.surv.post)]-cum.surv.post[1:(length(cum.surv.post)-1)])*times.post[1:(length(cum.surv.post)-1)])) 
  
  
  
}

output=list(med.tdt,expected.tdt,cum.surv.post,shape.pars,logscale.pars)
names(output)=c("med.tdt","expected.tdt","cum.surv","shape.pars","logscale.pars")
return(output)
}
```

```{r}
#Steps to this model:
#1) First fit weibull curves to each tdt curve (each temperature) for the data supplied
#2) Then fit a linear model to both weibull shape and scale vs temp
#3) Next, we deal with the fluctuating temp data:
#     start cumulative survival (S(t)) at 1 (S(t_0)=1)
#     for each timestep t_i:
#         Find the weibull shape and scale parameters corresponding to the temperature T_i at timestep t_i. These parameters give a cumulative survival function of time (time spent under the constant temperature used to make the Weibull TDT curve, which we will call t*. Not the fluctuating temperature t_i). This distribution has CDF F_w(t*), PDF f_w(t*), cumulative survival S_w(t*)=1-F_w(t*)
#         Find chance of surviving from time t_i-1 to t_i: 
#             i) First, we find: S_w^-1(S(t_i-1))=t*_i
#             ii) Calculate failure in that time interval f.rate_i=S(t_i)/S(t_i-1)
#             iii) Calculate cumulative mortality between t_i-1 and t_i as (t_i-(t_i-1))*f.rate_i
#             iiii)Let S_i=(S_i-1)-[(t_i-(t_i-1))*f_w(t*_i)]
#Note that this loop assumes the temperature is constant at T_i for the time interval from t_i-1 to t_i. You could alternatively take the max or average of the temperatures at these time points. 
#replace with shape="constant" if you want the model to assume constant shape
weibull.mod = function(TDT.dat,temp.dat,shape="linear"){
  #step 1
shape.vec = c()
shape.vec.var = c()
scale.vec = c()
scale.vec.var = c()
for (j in unique(TDT.dat$Tref)){
mod.j = flexsurvreg(Surv(time,event) ~ 1, data = TDT.dat[(TDT.dat$Tref==j),], dist=
                               "weibull")
shape.vec.var = c(shape.vec.var, mod.j$cov[[1,1]])
scale.vec.var = c(scale.vec.var, exp(mod.j$cov[[2,2]]))
shape.vec = c(shape.vec,mod.j$coefficients[[1]])
#exponentiate because the function flexsurvreg automatically puts scale on a log scale
scale.vec = c(scale.vec,exp(mod.j$coefficients[[2]]))
}

#step 2
shape.lm=lm(shape.vec~unique(TDT.dat$Tref))
shape.slope=lm(shape.vec~unique(TDT.dat$Tref))$coefficients[[2]]
shape.int=lm(shape.vec~unique(TDT.dat$Tref))$coefficients[[1]]
#constant shape lm
cons.shape.lm=lm(shape.vec~1)
cons.shape.int=cons.shape.lm$coefficients[[1]]
#note the log transformation
scale.lm=lm(log10(scale.vec)~unique(TDT.dat$Tref))
scale.slope=scale.lm$coefficients[[2]]
scale.int=scale.lm$coefficients[[1]]

shape.pars=c(shape.slope,shape.int,cons.shape.int)
logscale.pars=c(scale.slope,scale.int)

#predict under fluctuating temperatures with shape as a linear function of temperature
if (shape=="linear"){
#step 3
cum.surv = rep(NA,nrow(temp.dat))
cum.surv[1]=1
fail.rates = rep(0,nrow(temp.dat))
mean.list=c()
shape.list=c()
log.list=c()

for (i in 2:nrow(temp.dat)){
  T_i=temp.dat$Temperature[i]
  T_prev=temp.dat$Temperature[i-1]
  t_i=temp.dat$Time_min[i]
  t_prev=temp.dat$Time_min[i-1]
  t_diff=t_i-t_prev
  #untransform from log scale
  scale_i = 10^(scale.slope*mean(T_i,T_prev)+scale.int)
  shape_i = shape.slope*mean(T_i,T_prev)+shape.int
  mean.list=c(mean.list,scale_i*gamma(1+1/shape_i))
  log.list=c(log.list,cum.surv[i-1])
  #inverse CDF
  t_star_i=scale_i*(-log(cum.surv[i-1]))^(1/shape_i)
  #weibull pdf/failure rate
  #Get the proportion that made it th timestep i/prop that made it to i-1 to get the prop that died in the meantime
  fail.rates[i]=(1-pweibull(t_star_i,shape_i,scale_i))-(1-pweibull(t_star_i+t_diff,shape_i,scale_i))
  cum.surv[i]=cum.surv[i-1]-fail.rates[i]
}
med.tdt=temp.dat$Time_min[which.max(cum.surv<0.5)]
cum.surv.post=na.omit(cum.surv)
times.post=temp.dat$Time_min[1:length(cum.surv.post)]
expected.tdt=mean(-sum((cum.surv.post[2:length(cum.surv.post)]-cum.surv.post[1:(length(cum.surv.post)-1)])*times.post[2:length(cum.surv.post)]), -sum((cum.surv.post[2:length(cum.surv.post)]-cum.surv.post[1:(length(cum.surv.post)-1)])*times.post[1:(length(cum.surv.post)-1)]))
}

if (shape=="constant"){
 #step 3
cum.surv = rep(NA,nrow(temp.dat))
cum.surv[1]=1
fail.rates = rep(0,nrow(temp.dat))
mean.list=c()
shape.list=c()
log.list=c()

for (i in 2:nrow(temp.dat)){
  T_i=temp.dat$Temperature[i]
  T_prev=temp.dat$Temperature[i-1]
  t_i=temp.dat$Time_min[i]
  t_prev=temp.dat$Time_min[i-1]
  t_diff=t_i-t_prev
  #untransform from log scale
  scale_i = 10^(scale.slope*mean(T_i,T_prev)+scale.int)
  #this is the only line that is different
  shape_i = cons.shape.int
  mean.list=c(mean.list,scale_i*gamma(1+1/shape_i))
  log.list=c(log.list,cum.surv[i-1])
  #inverse CDF
  t_star_i=scale_i*(-log(cum.surv[i-1]))^(1/shape_i)
  #weibull pdf/failure rate
  #Get the proportion that made it th timestep i/prop that made it to i-1 to get the prop that died in the meantime
  fail.rates[i]=(1-pweibull(t_star_i,shape_i,scale_i))-(1-pweibull(t_star_i+t_diff,shape_i,scale_i))
  cum.surv[i]=cum.surv[i-1]-fail.rates[i]
}
med.tdt=temp.dat$Time_min[which.max(cum.surv<0.5)]
cum.surv.post=na.omit(cum.surv)
times.post=temp.dat$Time_min[1:length(cum.surv.post)]
expected.tdt=mean(-sum((cum.surv.post[2:length(cum.surv.post)]-cum.surv.post[1:(length(cum.surv.post)-1)])*times.post[2:length(cum.surv.post)]), -sum((cum.surv.post[2:length(cum.surv.post)]-cum.surv.post[1:(length(cum.surv.post)-1)])*times.post[1:(length(cum.surv.post)-1)])) 
  
  
  
}

output=list(med.tdt,expected.tdt,cum.surv.post,shape.pars,logscale.pars)
names(output)=c("med.tdt","expected.tdt","cum.surv","shape.pars","logscale.pars")
return(output)
}
```

```{r}
#for every time interval (t_i-1,t_i):
#1) Find max temperature over that time interval max(T_i,T_i-1)
#2) Find size of time interval (t_i-(t_i-1))
#3) Find damage accumulation rate: dd/dt=1/tKD(T)=1/(10^(Beta*T+alpha))
#4) Multiply rate by time interval to calculate accumulated damage for that time interval
#5) Add to total damage, record total damage at time t_i
#we start i-1 at the start time for the given trial group, and assume d=0 prior to this point. So, for trial group 1, i=2, but for trial group 3, which starts at about 117 mins, we start indexing at i=70 (calculations above)

jorg.mod = function(TDT.dat,temp.dat,KD.dat){
  #extract tdt coefficients
  tdt.lm = lm(log10.tcoma.~as.numeric(Tref),data=TDT.dat)
  tdt.slope=tdt.lm$coefficients[2]
  tdt.int=tdt.lm$coefficients[1]
  
  
  #injury ACC rate vector
acc.rates=rep(0,nrow(temp.dat))
#trial group 1
#initialize cumulative damage vector
cd.vec = rep(0,nrow(temp.dat))
#initialize timestep damage vector
td.vec = rep(0,nrow(temp.dat))
#initialize times vector
t.vec = temp.dat$Time_min
for (i in 2:nrow(temp.dat)){
  t_i = temp.dat$Time_min[i]
  t_prev = temp.dat$Time_min[i-1]
  T_i = temp.dat$Temperature[i]
  T_prev = temp.dat$Temperature[i-1]
  #1
  max.temp=max(T_i,T_prev)
  #2
  size.int=t_i-t_prev
  #3
  est.tKD = 10^(tdt.slope*max.temp+tdt.int)
  dd_dt = 1/est.tKD
  acc.rates[i]=dd_dt
  #4
  d.int = dd_dt*size.int
  td.vec[i-1]=d.int
  #5
  cd.vec[i]=cd.vec[i-1]+d.int
}
# 
# #now generate estimated damage at knockdown
# #initialize vector
dKD = rep(NA,nrow(KD.dat))

for (i in 1:nrow(KD.dat)){
   start.time = KD.dat$start[i]
   tKD = KD.dat$t_coma[i]
   dKD[i]=100*sum(td.vec[t.vec>=start.time & t.vec<=tKD])
}

est.tKD = rep(NA,nrow(KD.dat))
for (i in 1:nrow(KD.dat)){
  start.index.group = which.max(t.vec>=KD.dat$start[i])
  cd.group = cd.vec-cd.vec[start.index.group]
  est.tKD.index = which.max(cd.group>=1)
  est.tKD[i]=t.vec[est.tKD.index]
}
  
damage.df = data.frame(minutes=t.vec,cum.damage=cd.vec,interval.damage=td.vec)  
KD.dat$est.dKD = dKD  
KD.dat$est.tKD = est.tKD
#estimated and actual kdtimes starting at start time
KD.dat$est.tKD.adj = est.tKD-KD.dat$start
KD.dat$tcoma.adj=KD.dat$t_coma-KD.dat$start
ret.list=list(damage.df, KD.dat)
names(ret.list)=c("damage.df","KD.dat")


return(ret.list)
}
```




Need to calculate density. But this is difficult given that some of our curves are discrete and some are continuous. To make matters simpler and put all on an even playing field, I'll estimate densities by simulation. I'll generate 10000 unif(0,1) random variables, and treat these as cumulative survival values. Then, I'll map them to associated failure time values, giving me simulated random variables with the density of the model in question.
```{r}
#this function takes a dataframe with one column "times", a second column "cum.surv", and a third column "temp". These should be ordered in increasing time/decreasing cumulative survival. n is the number of random data points generated.
generate.density = function(cdf,n){
  
  temps.list = unique(cdf$temp)
  fail.ests = data.frame(
    tf = rep(NA,0),
    temp = rep(NA,0),
    rv = rep(NA,0))
    rvs = runif(n)
  
for (i in 1:length(temps.list)){
  temp_i = temps.list[i]
  cdf_i = cdf[cdf$temp==temp_i,]
#vector of n unif(0,1) random variables
#vector that will contain all of the simulated failure times
fail.ests.i = rep(NA,n)
for (j in 1:n){
  #the first time at which cumulative survival is less than or equal to our simulated random variable.
  #rounding our time up like this is practical, because if data is collected every dt minutes, and failure occurs just after time t, it won't be detected until time t+dt.
  fail.ests.i[j] = cdf_i$times[cdf_i$cum.surv<=rvs[j]][1]
}
#set an arbitrarily large value to the simulated points that are outside of our graph window. This way they will still be accounted for in the density metric, but won't show up on the graph.
fail.ests.i[is.na(fail.ests.i)==TRUE]=100000
fail.ests=rbind(fail.ests,data.frame(tf=fail.ests.i,temp=rep(temp_i,n),rv=rvs))
}
return(fail.ests)
}
```

```{r}
#This function takes data from the above models and turns it into a survival curve plot
#exp.data=experimental data
#data1->results from model 1 
plot.surv.curves = function(data1,data2,exp.data,modtitle1,modtitle2,title){
# Function to convert a vector into a data frame with group label
make_df <- function(vec, group_name) {
  data.frame(time = vec, status = 1, group = group_name)
}

# Combine all data
df <- bind_rows(
  make_df(data1, modtitle1),
  make_df(data2, modtitle2),
  make_df(exp.data, "Data")
)

# Set group order: modtitle1, modtitle2, then "Data"
df$group <- factor(df$group, levels = c(modtitle1, modtitle2, "Data"))

# Fit KM model
km_fit <- survfit(Surv(time, status) ~ group, data = df)
tidy_km <- broom::tidy(km_fit)

# Clean and reorder strata names for matching
tidy_km$strata <- case_match(tidy_km$strata,
                         paste0("group=",modtitle1) ~ modtitle1,
                         paste0("group=",modtitle2)  ~ modtitle2,
                         "group=Data" ~ "Data")

# Set factor order for legend
tidy_km$strata <- factor(tidy_km$strata, levels = c(modtitle1, modtitle2, "Data"))

p = ggplot(tidy_km, aes(x = time, y = estimate, color = strata, linetype = strata)) +
  geom_step(linewidth = 1.6) +
  labs(
    y = "Cumulative Survival",
    x = "Time (minutes)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    legend.title = element_blank(),
    axis.title = element_blank()
  )+
  ggtitle(title)
return(p)}
```

```{r}
#We next want to extract log-likelihoods
#The problem is that the dynamic.landscape function returns a CDF (or really 1-CDF=survival curve), but the log likelihood function estimates a PDF through samples failure times. So we have to sample failure times through simulation and obtain a PDF, since it is not an analytical distribution.
Surv.to.tf.sims = function(Surv.df,n=10000){
  sims.vec=rep(NA,n)
  unifs = runif(n)*100
  for (i in 1:n){
    sims.vec[i] = Surv.df$time[which.max(Surv.df$alive<=unifs[i])]
  }
  return(sims.vec)
}
```

```{r}
#This function takes data from the above models and turns it into a survival curve plot
#exp.data=experimental data
#data1->results from model 1 
plot.surv.curves = function(data1,data2,exp.data,modtitle1,modtitle2,title){
# Function to convert a vector into a data frame with group label
make_df <- function(vec, group_name) {
  data.frame(time = vec, status = 1, group = group_name)
}

# Combine all data
df <- bind_rows(
  make_df(data1, modtitle1),
  make_df(data2, modtitle2),
  make_df(exp.data, "Data")
)

# Set group order: modtitle1, modtitle2, then "Data"
df$group <- factor(df$group, levels = c(modtitle1, modtitle2, "Data"))

# Fit KM model
km_fit <- survfit(Surv(time, status) ~ group, data = df)
tidy_km <- broom::tidy(km_fit)

# Clean and reorder strata names for matching
tidy_km$strata <- case_match(tidy_km$strata,
                         paste0("group=",modtitle1) ~ modtitle1,
                         paste0("group=",modtitle2)  ~ modtitle2,
                         "group=Data" ~ "Data")

# Set factor order for legend
tidy_km$strata <- factor(tidy_km$strata, levels = c(modtitle1, modtitle2, "Data"))

p = ggplot(tidy_km, aes(x = time, y = estimate, color = strata, linetype = strata)) +
  geom_step(linewidth = 1.6) +
  labs(
    y = "Cumulative Survival",
    x = "Time (minutes)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
    panel.grid = element_blank(),
    legend.title = element_blank(),
    axis.title = element_blank()
  )+
  ggtitle(title)
return(p)}
```